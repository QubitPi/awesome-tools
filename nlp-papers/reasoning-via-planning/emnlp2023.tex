\pdfoutput=1

\documentclass[11pt]{article}
\usepackage{EMNLP2023}
\usepackage{times}
\usepackage{latexsym}
\usepackage{graphicx}
\usepackage{listings}
\lstset{
  backgroundcolor=\color{gray!8},
  basicstyle=\ttfamily,
  columns=fullflexible
}
% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{inconsolata}
\usepackage{xspace}
\usepackage{booktabs}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath, amsfonts, amssymb}

\usepackage{makecell}
\usepackage[normalem]{ulem}
\usepackage{pifont}% http://ctan.org/pkg/pifont
\newcommand{\cmark}{{\ding{51}}}
\newcommand{\xmark}{{\ding{55}}}
\NewDocumentCommand{\hsb}{ mO{} }{\textcolor{pink}{\textsuperscript{\textit{Shibo}}\textsf{\textbf{\small[#1]}}}}

\NewDocumentCommand{\gy}{ mO{} }{\textcolor{purple}{\textsuperscript{\textit{Yi}}\textsf{\textbf{\small[#1]}}}}

\NewDocumentCommand{\hzt}{ mO{} }{\textcolor{red}{\textsuperscript{\textit{ZT}}\textsf{\textbf{\small[#1]}}}}

\NewDocumentCommand{\zhen}{ mO{} }{\textcolor{blue}{\textsuperscript{\textit{ZW}}\text{\text{\small[#1]}}}}

\NewDocumentCommand{\jjh}{ mO{} }{\textcolor{cyan}{\textsuperscript{\textit{Joshua}}\text{\text{\small[#1]}}}}


\newcommand{\dummyfig}[1]{
  \centering
  \fbox{
    \begin{minipage}[c][0.3\textheight][c]{0.5\textwidth}
      \centering{#1}
    \end{minipage}
  }
}

\def\blocksworld{{Blocksworld}\xspace}
\def\ours{{RAP}\xspace}

% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{Reasoning with Language Model is
Planning with World Model}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a separate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{%
Shibo Hao\textsuperscript{$*\clubsuit$} \ Yi Gu\thanks{\, equal contribution}\textsuperscript{$*\clubsuit$} \
Haodi Ma\textsuperscript{$\diamondsuit$}\  Joshua Jiahua Hong\textsuperscript{$\clubsuit$} \\ \textbf{Zhen Wang\textsuperscript{$\clubsuit$ $\spadesuit$} \
Daisy Zhe Wang\textsuperscript{$\diamondsuit$}\ Zhiting Hu\textsuperscript{$\clubsuit$}}  \vspace{5pt} \\
\textsuperscript{$\clubsuit$}UC San Diego, \textsuperscript{$\diamondsuit$}University of Florida\\
\textsuperscript{$\spadesuit$}Mohamed bin Zayed University of Artificial Intelligence \\
\texttt{\{s5hao, yig025, jjhong, zhw085, zhh019\}@ucsd.edu}  \\
\texttt{\{ma.haodi, daisyw\}@ufl.edu}}
 
% \author{First Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\\And
%   Second Author \\
%   Affiliation / Address line 1 \\
%   Affiliation / Address line 2 \\
%   Affiliation / Address line 3 \\
%   \texttt{email@domain} \\}

\begin{document}
\maketitle
\begin{abstract}
Large language models (LLMs) have shown remarkable reasoning capabilities, particularly with chain-of-thought (CoT) prompting. However, LLMs sometimes still struggle with problems that are easy for humans, such as generating action plans to achieve given goals in an environment, or performing complex math or logical reasoning. The deficiency stems from the key fact that LLMs lack an internal \emph{world model} to predict the world \emph{state} (e.g., environment status, intermediate variable values) and simulate long-term outcomes of actions. This prevents LLMs from performing deliberate planning akin to human brains, which involves exploring alternative reasoning paths, anticipating future states and rewards, and iteratively refining existing reasoning steps. To overcome the limitations, we propose a new LLM reasoning framework, {\bf \underline{R}easoning vi\underline{a} \underline{P}lanning (RAP)}. RAP repurposes the LLM as both a world model and a reasoning agent, and incorporates a principled planning algorithm based on Monte Carlo Tree Search for strategic exploration in the vast reasoning space. During reasoning, the LLM (as agent) incrementally builds a reasoning tree under the guidance of the LLM (as world model) and rewards, and efficiently obtains a high-reward reasoning path with a proper balance between exploration \emph{vs.} exploitation. 
% As a general reasoning framework, 
We apply RAP to various challenging reasoning problems including plan generation, math reasoning, and logical inference, and demonstrate its superiority over strong baselines. RAP with LLaMA-33B even surpasses CoT with GPT-4, achieving 33\% relative improvement in a plan generation setting.\footnote{The code is available at \url{https://github.com/Ber666/llm-reasoners}}
\end{abstract}
\input{sections/intro}
\input{sections/related_works}
\input{sections/method}
\input{sections/experiment}
\input{sections/conclusion}
\section*{Limitations}
In this work, we mainly focus on utilizing frozen LLMs, whose abilities might be bounded by the pre-training. In the future, it is worth exploring how to fine-tune LLMs to better reason and serve as a world model \cite{xiang2023language}, as well as how to combine external tools \cite{hao2023toolkengpt,schick2023toolformer} with RAP to solve more complex real-world problems.

\section*{Ethics Statement}
In this paper, we primarily focus on the applications on
plan generation, mathematical reasoning, and logical reasoning, posing no significant ethical concerns. We recognize that future research on border applications of reasoning with LLMs may pose a risk of misuse, and we recommend careful consideration of all aspects of safety before relevant techniques are applied to the real world.
%Scientific work published at EMNLP 2023 must comply with the \href{https://www.aclweb.org/portal/content/acl-code-ethics}{ACL Ethics Policy}. We encourage all authors to include an explicit ethics statement on the broader impact of the work, or other ethical considerations after the conclusion but before the references. The ethics statement will not count toward the page limit (8 pages for long, 4 pages for short papers).

% Entries for the entire Anthology, followed by custom entries
\bibliography{main}
\bibliographystyle{acl_natbib}


\appendix
\input{sections/appendix}

\end{document}
